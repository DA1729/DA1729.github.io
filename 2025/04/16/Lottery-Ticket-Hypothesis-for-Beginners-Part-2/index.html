<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Lottery Ticket Hypothesis Part 2 | da1729&#39;s Blog</title>
  
  <!-- SEO Meta Tags -->
  <meta name="description" content="">
  <meta name="keywords" content="">
  <meta name="author" content="Daksh Pandey">
  
  <!-- Open Graph -->
  <meta property="og:title" content="Lottery Ticket Hypothesis Part 2">
  <meta property="og:description" content="">
  <meta property="og:type" content="post">
  <meta property="og:url" content="/2025/04/16/Lottery-Ticket-Hypothesis-for-Beginners-Part-2/">
  <meta property="og:site_name" content="da1729&#39;s Blog">
  
  <!-- CSS -->
  
<link rel="stylesheet" href="/css/style.css">

  
  <!-- RSS Feed -->
  
  
  <!-- Favicon -->
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div class="page-wrapper">
    <!-- Header -->
    <header class="header">
      <h1>
        <a href="/" class="site-title">da1729&#39;s Blog</a>
      </h1>
      
        <p class="site-subtitle">cryptography, digital design, embedded, rf, ...</p>
      
      
      <!-- Navigation -->
      <nav class="nav">
        
          <a href="/" class="nav-link">Home</a>
        
          <a href="/quick" class="nav-link">Quick Posts</a>
        
          <a href="/archives" class="nav-link">Archives</a>
        
          <a href="/about" class="nav-link">About</a>
        
        
        <!-- Social Links -->
        
          
            <a href="https://github.com/DA1729" class="nav-link" target="_blank" rel="noopener">github</a>
          
            <a href="https://x.com/sp0oky_daksh" class="nav-link" target="_blank" rel="noopener">twitter</a>
          
            <a href="mailto:dakshpandey177@gmail.com" class="nav-link" target="_blank" rel="noopener">email</a>
          
            <a href="https://sp0oky-portfolio.vercel.app/" class="nav-link" target="_blank" rel="noopener">portfolio</a>
          
        
      </nav>
    </header>

    <!-- Main Content -->
    <div class="container">
      <div class="content">
        <main class="main-content">
          <!-- Individual Post Page -->
<article class="article-card">
  <header class="article-header">
    <div class="article-meta">
      <time datetime="2025-04-16T12:19:20.000Z">
        April 16, 2025
      </time>
      
      
        <span> • Updated: September 27, 2025</span>
      
    </div>
    
    <h1 class="article-title">Lottery Ticket Hypothesis Part 2</h1>
    
    
      <div class="article-tags">
        
          <a href="/tags/AI-Acceleration/" class="tag">#AI Acceleration</a>
        
      </div>
    
  </header>
  
  <div class="article-content">
    <div class="post-content">
      <h2><span id="iterative-pruning-and-finding-the-winning-ticket">Iterative Pruning and Finding the Winning Ticket</span></h2><p>So far, we’ve talked about the idea that there’s a smaller subnetwork—our so-called winning ticket—hidden within a big neural network. But how do we actually find this winning ticket? That’s where <strong>iterative pruning</strong> steps in.</p>
<h3><span id="the-iterative-pruning-process">The Iterative Pruning Process</span></h3><span id="more"></span>

<p>Instead of pruning once and hoping we get lucky, iterative pruning does the following:</p>
<ul>
<li><strong>Train the full network</strong> for a fixed number of iterations.</li>
<li><strong>Prune a small percentage</strong> (say, 10%-20%) of the lowest magnitude weights.</li>
<li><strong>Reset the remaining weights back</strong> to their original initialization.</li>
<li><strong>Repeat steps 1–3</strong> for several rounds.</li>
</ul>
<p>This slow and steady process lets us uncover subnetworks that are small but still highly capable—our winning tickets.</p>
<h3><span id="why-iterative-pruning-works-better">Why Iterative Pruning Works Better</span></h3><p>Turns out, one-shot pruning (cutting lots of weights at once) often fails to find the best subnetworks, especially when we go too small. Iterative pruning, on the other hand, carefully preserves the parts of the network that matter, leading to <strong>better performance at smaller sizes</strong>.</p>
<hr>
<p>In the experiments, they could reduce the network size by up to 90%, and the resulting subnetworks still learned faster and better than the full network!</p>
<hr>
<h2><span id="do-winning-tickets-generalize-better">Do Winning Tickets Generalize Better?</span></h2><p>Now here’s where things get spicy. When comparing test accuracies, the researchers noticed something curious:</p>
<ul>
<li>The winning tickets not only learned faster,</li>
<li>They often had <strong>better generalization</strong> than the original model!</li>
</ul>
<p>This means that they didn’t just memorize training data—they actually learned to perform better on unseen test data.</p>
<p>This idea is related to something called <strong>Occam’s Hill</strong>—too big and you overfit, too small and you underfit. Winning tickets land at a sweet spot: small enough to avoid overfitting, but just right to still learn effectively.</p>
<h2><span id="initialization-matters-a-lot">Initialization Matters (A Lot)</span></h2><p>Another key takeaway: it’s not just the structure of the subnetwork that matters. It’s also the <strong>exact initial weights</strong>.</p>
<p>If you take a winning ticket’s structure and randomly reinitialize it, it <strong>loses its magic</strong>—learning slows down and performance drops.</p>
<h2><span id="expanding-to-convolutional-networks">Expanding to Convolutional Networks</span></h2><p>The authors didn’t just test on simple fully-connected networks like LeNet on MNIST. They also ran experiments on <strong>convolutional networks</strong> like Conv-2, Conv-4, and Conv-6 on CIFAR-10.</p>
<p>Surprise surprise: they found <strong>winning tickets</strong> there too. In fact, the same pattern repeated:</p>
<ul>
<li>Winning tickets learn faster</li>
<li>They reach higher accuracy</li>
<li>They generalize better</li>
<li>Initialization still matters</li>
</ul>
<p>The success wasn’t limited to toy datasets—this was happening on moderately complex image classification tasks too.</p>
<h2><span id="drop-out-pruning">Drop-Out + Pruning</span></h2><p>What happens when you combine <strong>dropout</strong> with pruning?*</p>
<p>Turns out, dropout helps too! Dropout already encourages the network to be robust to missing connections. So when you prune, the network is more resilient.</p>
<p>When they trained networks <strong>with dropout</strong> and applied iterative pruning, the test accuracy <strong>improved even further</strong>. This hints that dropout may help in preparing the network for successful pruning.</p>
<h2><span id="the-big-leagues-vgg-19-and-resnet-18">The Big Leagues: VGG-19 and RESNET-18</span></h2><p>Taking it up a notch, the paper also tested on deeper, real-world architectures:</p>
<ul>
<li><strong>VGG-19</strong></li>
<li><strong>ResNet-18</strong></li>
</ul>
<p>The pattern mostly held up—but with a twist. For these deep networks, iterative pruning only worked well if they used <strong>learning rate warm-up</strong>.</p>
<p>Without warm-up, pruning failed to find winning tickets. With warm-up (i.e., slowly increasing the learning rate at the beginning of training), they were back in business.</p>
<p>So yes—winning tickets exist even in deep networks, but only if you treat them with care.</p>
<h2><span id="key-takeaways">Key Takeaways</span></h2><ul>
<li>Big neural networks contain hidden winning tickets—smaller subnetworks that can be trained to match or exceed full network performance.</li>
<li>You find them by <strong>pruning</strong> and <strong>resetting</strong> repeatedly.</li>
<li>These subnetworks not only match accuracy, but often learn <strong>faster</strong> and generalize <strong>better</strong>.</li>
<li>The <strong>initialization</strong> is crucial—you can’t just randomly reinitialize and expect the same results.</li>
<li>Even deeper networks like VGG and ResNet have winning tickets, but they may require careful tuning (e.g., learning rate warm-up).</li>
<li>Pruning isn’t just for compression—it might teach us something deep about how neural networks work.</li>
</ul>
<p>Now, what I am trying to do is replecating the results found by the authors myself. So stick around and keep a look over my <a target="_blank" rel="noopener" href="https://github.com/DA1729">GitHub</a>.</p>
<p>peace. da1729</p>
<h2><span id="references">References</span></h2><p>[1] @misc{frankle2019lotterytickethypothesisfinding,<br>      title&#x3D;{The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},<br>      author&#x3D;{Jonathan Frankle and Michael Carbin},<br>      year&#x3D;{2019},<br>      eprint&#x3D;{1803.03635},<br>      archivePrefix&#x3D;{arXiv},<br>      primaryClass&#x3D;{cs.LG},<br>      url&#x3D;{<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.03635">https://arxiv.org/abs/1803.03635</a>},<br>}</p>

    </div>
  </div>
</article>

<!-- Post Navigation -->

  <nav class="post-nav mt-2">
    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px;">
      
        <div class="widget">
          <div class="widget-title">Previous Post</div>
          <a href="/2025/07/03/Breaking-LWE-Encryption/">An Empirical Analysis of LWE Robustness Against Machine Learning Distinguishers</a>
        </div>
      
      
      
        <div class="widget">
          <div class="widget-title">Next Post</div>
          <a href="/2025/04/13/Lottery-Ticket-Hypothesis-for-Beginners/">Lottery Ticket Hypothesis Part-1</a>
        </div>
      
    </div>
  </nav>


<!-- Related Posts -->

        </main>
        
        <!-- Sidebar -->
        <aside class="sidebar">
          <!-- Sidebar Widgets -->

<!-- Recent Posts Widget -->

  <div class="widget">
    <h3 class="widget-title">Recent Posts</h3>
    <ul>
      
        <li>
          <a href="/2025/12/03/Mult-Party-Computation-part-2/">Multi-Party Computation part 2</a>
          <div style="font-size: 0.8em; color: var(--text-secondary); margin-top: 4px;">
            Dec 3, 2025
          </div>
        </li>
      
        <li>
          <a href="/2025/12/01/Multi-Party-Computation/">Multi-Party Computation part 1</a>
          <div style="font-size: 0.8em; color: var(--text-secondary); margin-top: 4px;">
            Dec 1, 2025
          </div>
        </li>
      
        <li>
          <a href="/2025/09/27/Need-for-Gadget-Decomposition-in-LWE-Based-Cryptosystems/">Need for Gadget Decomposition in LWE Based Cryptosystems</a>
          <div style="font-size: 0.8em; color: var(--text-secondary); margin-top: 4px;">
            Sep 27, 2025
          </div>
        </li>
      
        <li>
          <a href="/2025/09/14/AGI-running-on-Quantum-Chip/">AGI running on Quantum Chip?</a>
          <div style="font-size: 0.8em; color: var(--text-secondary); margin-top: 4px;">
            Sep 14, 2025
          </div>
        </li>
      
        <li>
          <a href="/2025/08/15/Ring-LWE-and-CKKS-Mathematical-Foundations/">Ring-LWE and CKKS: Mathematical Foundations for Homomorphic Encryption</a>
          <div style="font-size: 0.8em; color: var(--text-secondary); margin-top: 4px;">
            Aug 15, 2025
          </div>
        </li>
      
    </ul>
  </div>


<!-- Categories Widget -->


<!-- Tags Widget -->

  <div class="widget">
    <h3 class="widget-title">Tags</h3>
    <div style="display: flex; flex-wrap: wrap; gap: 8px;">
      
        <a href="/tags/AI-Acceleration/" class="tag">
          #AI - Acceleration
        </a>
      
        <a href="/tags/AI-Acceleration/" class="tag">
          #AI Acceleration
        </a>
      
        <a href="/tags/Abstract-Algebra/" class="tag">
          #Abstract Algebra
        </a>
      
        <a href="/tags/Analog/" class="tag">
          #Analog
        </a>
      
        <a href="/tags/Cryptanalysis/" class="tag">
          #Cryptanalysis
        </a>
      
        <a href="/tags/Cryptography/" class="tag">
          #Cryptography
        </a>
      
        <a href="/tags/Fully-Homomorphic-Encryption/" class="tag">
          #Fully Homomorphic Encryption
        </a>
      
        <a href="/tags/Hardware-Acceleration/" class="tag">
          #Hardware Acceleration
        </a>
      
        <a href="/tags/Philosphy/" class="tag">
          #Philosphy
        </a>
      
        <a href="/tags/Post-Quantum-Cryptography/" class="tag">
          #Post Quantum Cryptography
        </a>
      
        <a href="/tags/Post-Quantum-Cryptography/" class="tag">
          #Post-Quantum Cryptography
        </a>
      
        <a href="/tags/Ring-Theory/" class="tag">
          #Ring Theory
        </a>
      
        <a href="/tags/Secure-Computing/" class="tag">
          #Secure Computing
        </a>
      
        <a href="/tags/VLSI/" class="tag">
          #VLSI
        </a>
      
    </div>
  </div>


<!-- Archive Widget -->

  <div class="widget">
    <h3 class="widget-title">Archive</h3>
    <ul>
      
      
        
          <li>
            <a href="/archives/2025/">
              December 2025 (2)
            </a>
          </li>
        
          <li>
            <a href="/archives/2025/">
              September 2025 (2)
            </a>
          </li>
        
          <li>
            <a href="/archives/2025/">
              August 2025 (1)
            </a>
          </li>
        
          <li>
            <a href="/archives/2025/">
              July 2025 (1)
            </a>
          </li>
        
          <li>
            <a href="/archives/2025/">
              April 2025 (2)
            </a>
          </li>
        
          <li>
            <a href="/archives/2025/">
              March 2025 (2)
            </a>
          </li>
        
      
    </ul>
  </div>


<!-- About Widget -->
<div class="widget">
  <h3 class="widget-title">About</h3>
  <p style="font-size: 0.9em; line-height: 1.6;">
    Welcome to my blog! Here I write about various topics including technology, programming, and more.
  </p>
  
  
    <div style="margin-top: 15px;">
      <strong style="font-size: 0.9em;">Find me on:</strong>
      <div style="margin-top: 8px; display: flex; flex-wrap: wrap; gap: 8px;">
        
          <a href="https://github.com/DA1729" class="tag" target="_blank" rel="noopener">
            github
          </a>
        
          <a href="https://x.com/sp0oky_daksh" class="tag" target="_blank" rel="noopener">
            twitter
          </a>
        
          <a href="mailto:dakshpandey177@gmail.com" class="tag" target="_blank" rel="noopener">
            email
          </a>
        
          <a href="https://sp0oky-portfolio.vercel.app/" class="tag" target="_blank" rel="noopener">
            portfolio
          </a>
        
      </div>
    </div>
  
  
  <div style="margin-top: 15px; padding-top: 15px; border-top: 1px solid var(--border-color);">
    <p style="font-size: 0.8em; color: var(--text-secondary); opacity: 0.8;">
      Theme designed with 
      <a href="https://claude.ai/code" target="_blank" rel="noopener" style="color: var(--link-color); text-decoration: none;">Claude Code</a>
    </p>
  </div>
</div>
        </aside>
      </div>
    </div>

    <!-- Footer -->
    <footer class="footer">
      <p>© 2025 Daksh Pandey. Portfolio-inspired theme crafted with Claude Code.</p>
    </footer>
  </div>

  <!-- JavaScript -->
  
<script src="/js/main.js"></script>

  
  <!-- Math Support -->
  
    <script>
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          ignoreHtmlClass: 'tex2jax_ignore',
          processHtmlClass: 'tex2jax_process'
        }
      };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  
</body>
</html>